{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from scipy.stats import zscore\n",
    "\n",
    "class Elo:\n",
    "    WIN = 1.0\n",
    "    DRAW = 0.5\n",
    "    LOSS = 0.0\n",
    "    K_FACTOR = 10\n",
    "    INITIAL = 1200\n",
    "    BETA = 200\n",
    "\n",
    "    def __init__(self, k_factor=K_FACTOR, initial=INITIAL, beta=BETA):\n",
    "        self.k_factor = k_factor\n",
    "        self.initial = initial\n",
    "        self.beta = beta\n",
    "\n",
    "    def expect(self, rating, other_rating):\n",
    "        \"\"\"The 'E' function in Elo. Calculates the expected score of the first rating by the second rating.\"\"\"\n",
    "        diff = float(other_rating) - float(rating)\n",
    "        f_factor = 2 * self.beta  # rating disparity\n",
    "        return 1.0 / (1 + 10 ** (diff / f_factor))\n",
    "\n",
    "    def adjust(self, rating, series):\n",
    "        \"\"\"Calculates the adjustment value based on a series of matches.\"\"\"\n",
    "        return sum(score - self.expect(rating, other_rating) for score, other_rating in series)\n",
    "\n",
    "    def rate(self, rating, series):\n",
    "        \"\"\"Calculates a new rating based on the match results.\"\"\"\n",
    "        new_rating = float(rating) + self.k_factor * self.adjust(rating, series)\n",
    "        return new_rating\n",
    "\n",
    "    def rate_1vs1(self, rating1, rating2, drawn=False):\n",
    "        \"\"\"Calculates the new ratings for a one-on-one match.\"\"\"\n",
    "        scores = (self.DRAW, self.DRAW) if drawn else (self.WIN, self.LOSS)\n",
    "        new_rating1 = self.rate(rating1, [(scores[0], rating2)])\n",
    "        new_rating2 = self.rate(rating2, [(scores[1], rating1)])\n",
    "        return new_rating1, new_rating2\n",
    "\n",
    "elo_system = Elo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_37184\\2502048867.py:2: UserWarning: Parsing dates in MM/DD/YYYY format when dayfirst=True was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  nfl = pd.read_csv(\"spreadspoke_scores.csv\", parse_dates=['schedule_date'], dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     schedule_date  schedule_season schedule_week  schedule_playoff  \\\n",
      "2512    1979-02-09             1979             1             False   \n",
      "2693    1979-02-12             1979            14             False   \n",
      "2639    1979-04-11             1979            10             False   \n",
      "2708    1979-09-12             1979            15             False   \n",
      "2541    1979-09-16             1979             3             False   \n",
      "\n",
      "                team_home  score_home  score_away            team_away  \\\n",
      "2512  St. Louis Cardinals        21.0        22.0       Dallas Cowboys   \n",
      "2693  St. Louis Cardinals        13.0        10.0  San Francisco 49ers   \n",
      "2639  St. Louis Cardinals        37.0         7.0    Minnesota Vikings   \n",
      "2708  St. Louis Cardinals        29.0        20.0      New York Giants   \n",
      "2541  St. Louis Cardinals        21.0        24.0  Pittsburgh Steelers   \n",
      "\n",
      "     team_favorite_id  spread_favorite  ...    spread_type spread_outlier  \\\n",
      "2512              DAL             -4.0  ...  Home Underdog     No Outlier   \n",
      "2693              ARI             -6.0  ...  Home Favorite     No Outlier   \n",
      "2639              ARI             -5.0  ...  Home Favorite     No Outlier   \n",
      "2708              ARI             -2.0  ...  Home Favorite     No Outlier   \n",
      "2541              PIT             -6.0  ...  Home Underdog     No Outlier   \n",
      "\n",
      "      over_under_outlier  team_home_elo_pre  team_away_elo_pre  \\\n",
      "2512          No Outlier         930.217786        1065.188548   \n",
      "2693          No Outlier         930.217786        1076.854640   \n",
      "2639          No Outlier         930.217786        1031.568433   \n",
      "2708           Under 1sd         930.217786         919.606786   \n",
      "2541          No Outlier         930.217786        1073.653709   \n",
      "\n",
      "      elo_pre_difference team_home_win_prob team_away_win_prob  \\\n",
      "2512         -134.970762           0.250949           0.749051   \n",
      "2693         -146.636854           0.238537           0.761463   \n",
      "2639         -101.350647           0.289045           0.710955   \n",
      "2708           10.611000           0.436464           0.563536   \n",
      "2541         -143.435923           0.241900           0.758100   \n",
      "\n",
      "     team_home_result team_away_result  \n",
      "2512             Loss              Win  \n",
      "2693              Win             Loss  \n",
      "2639              Win             Loss  \n",
      "2708              Win             Loss  \n",
      "2541             Loss              Win  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_37184\\2502048867.py:103: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  nfl['win_pct'] = nfl.groupby('team_home_id')['team_home_result'].apply(lambda x: x.eq('Win').rolling(window=16, min_periods=1).mean())\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Column not found: spread_home_cover_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(nfl\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m    103\u001b[0m nfl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin_pct\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m nfl\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_home_id\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_home_result\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39meq(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWin\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m--> 104\u001b[0m nfl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcover_pct\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mteam_home_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspread_home_cover_count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index(\u001b[38;5;241m0\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m nfl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mover_pct\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m nfl\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_home_id\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mover_under_result_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index(\u001b[38;5;241m0\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    107\u001b[0m nfl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore_avg_pts_for\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m nfl\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_home_id\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index(\u001b[38;5;241m0\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\groupby\\generic.py:1416\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise warning\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing with multiple keys (implicitly converted to a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof keys) will be deprecated, use a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1414\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1415\u001b[0m     )\n\u001b[1;32m-> 1416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\base.py:248\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m     subset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\n\u001b[0;32m    250\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m subset\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: spread_home_cover_count'"
     ]
    }
   ],
   "source": [
    "# Load the CSV data\n",
    "nfl = pd.read_csv(\"spreadspoke_scores.csv\", parse_dates=['schedule_date'], dayfirst=True)\n",
    "nfl = nfl.dropna(subset=['over_under_line'])\n",
    "nfl['over_under_line'] = pd.to_numeric(nfl['over_under_line'], errors='coerce')\n",
    "\n",
    "# Load team data\n",
    "teams = pd.read_csv(\"nfl_teams.csv\")\n",
    "team_names = teams['team_name'].tolist()\n",
    "team_ids = teams['team_id'].tolist()\n",
    "\n",
    "# Assign team IDs to home and away teams\n",
    "nfl['team_home_id'] = nfl['team_home'].apply(lambda x: teams.loc[teams['team_name'] == x, 'team_id'].values[0] if x in team_names else np.nan)\n",
    "nfl['team_away_id'] = nfl['team_away'].apply(lambda x: teams.loc[teams['team_name'] == x, 'team_id'].values[0] if x in team_names else np.nan)\n",
    "\n",
    "# Create a unique game ID\n",
    "nfl['game_id'] = nfl.apply(lambda row: f\"{row['schedule_date'].strftime('%Y%m%d')}{row['team_away_id']}{row['team_home_id']}\", axis=1)\n",
    "\n",
    "# Load stadium data\n",
    "stadiums = pd.read_csv(\"nfl_stadiums.csv\")\n",
    "stadium_names = stadiums['stadium_name'].tolist()\n",
    "stadium_types = stadiums['stadium_type'].tolist()\n",
    "\n",
    "# Assign stadium types\n",
    "nfl['stadium_type'] = nfl['stadium'].apply(lambda x: stadium_types[stadium_names.index(x)] if x in stadium_names else np.nan)\n",
    "\n",
    "# Add columns for first and last week of the season\n",
    "nfl['schedule_week_1'] = nfl['schedule_week'] == 1\n",
    "nfl['schedule_week_last'] = nfl.apply(lambda row: row['schedule_week'] == (18 if row['schedule_season'] in [1993, 1999] else 17), axis=1)\n",
    "\n",
    "# Add day of week and month\n",
    "nfl['schedule_day'] = nfl['schedule_date'].dt.day_name()\n",
    "nfl['schedule_month'] = nfl['schedule_date'].dt.month_name()\n",
    "nfl['schedule_sunday'] = nfl['schedule_day'] == 'Sunday'\n",
    "\n",
    "# Add divisional information\n",
    "nfl['team_home_division'] = nfl['team_home'].apply(lambda x: teams.loc[teams['team_name'] == x, 'team_division'].values[0] if x in team_names else np.nan)\n",
    "nfl['team_away_division'] = nfl['team_away'].apply(lambda x: teams.loc[teams['team_name'] == x, 'team_division'].values[0] if x in team_names else np.nan)\n",
    "\n",
    "nfl['division_matchup'] = nfl.apply(lambda row: row['team_home_division'] == row['team_away_division'], axis=1)\n",
    "\n",
    "# Spread and over/under analysis\n",
    "nfl['team_home_favorite'] = nfl['team_favorite_id'] == nfl['team_home_id']\n",
    "nfl['spread_home'] = np.where(nfl['team_home_favorite'], nfl['spread_favorite'], -nfl['spread_favorite'])\n",
    "nfl['spread_away'] = -nfl['spread_home']\n",
    "\n",
    "nfl['spread_type'] = nfl['spread_home'].apply(lambda x: 'Pick' if x == 0 else ('Home Underdog' if x > 0 else 'Home Favorite'))\n",
    "nfl['spread_outlier'] = nfl['spread_favorite'].apply(lambda x: '2TD+' if abs(x) > 14.1 else ('1TD1FG+' if abs(x) > 10.1 else ('1TD+' if abs(x) > 7.1 else 'No Outlier')))\n",
    "\n",
    "nfl['over_under_outlier'] = nfl['over_under_line'].apply(lambda x: 'Under 2sd' if x < 33 else ('Under 1sd' if x < 37 else ('Over 2sd' if x > 50 else ('Over 1sd' if x > 46 else 'No Outlier'))))\n",
    "\n",
    "# Elo calculation\n",
    "elo_ratings = {}\n",
    "initial_elo = 1000\n",
    "\n",
    "def update_elo(winner, loser, tie=False):\n",
    "    if tie:\n",
    "        return elo_system.rate_1vs1(elo_ratings[winner], elo_ratings[loser], drawn=True)\n",
    "    else:\n",
    "        return elo_system.rate_1vs1(elo_ratings[winner], elo_ratings[loser])\n",
    "\n",
    "for index, row in nfl.iterrows():\n",
    "    home_team = row['team_home_id']\n",
    "    away_team = row['team_away_id']\n",
    "    \n",
    "    # Initialize elo if not already set\n",
    "    if home_team not in elo_ratings:\n",
    "        elo_ratings[home_team] = initial_elo\n",
    "    if away_team not in elo_ratings:\n",
    "        elo_ratings[away_team] = initial_elo\n",
    "    \n",
    "    if row['score_home'] > row['score_away']:\n",
    "        winner, loser = home_team, away_team\n",
    "    elif row['score_away'] > row['score_home']:\n",
    "        winner, loser = away_team, home_team\n",
    "    else:\n",
    "        winner, loser = home_team, away_team\n",
    "        tie = True\n",
    "    \n",
    "    elo_ratings[winner], elo_ratings[loser] = update_elo(winner, loser, tie=False)\n",
    "\n",
    "nfl['team_home_elo_pre'] = nfl['team_home_id'].apply(lambda x: elo_ratings.get(x, initial_elo))\n",
    "nfl['team_away_elo_pre'] = nfl['team_away_id'].apply(lambda x: elo_ratings.get(x, initial_elo))\n",
    "\n",
    "# Calculate pre-game elo difference\n",
    "nfl['elo_pre_difference'] = nfl['team_home_elo_pre'] - nfl['team_away_elo_pre']\n",
    "\n",
    "# Probability of home team win\n",
    "def win_probability(home_elo, away_elo):\n",
    "    return 1 / (1 + 10 ** ((away_elo - home_elo + 55) / 400))\n",
    "\n",
    "nfl['team_home_win_prob'] = nfl.apply(lambda row: win_probability(row['team_home_elo_pre'], row['team_away_elo_pre']), axis=1)\n",
    "nfl['team_away_win_prob'] = 1 - nfl['team_home_win_prob']\n",
    "\n",
    "# Game outcomes\n",
    "nfl['team_home_result'] = nfl.apply(lambda row: 'Win' if row['score_home'] > row['score_away'] else ('Tie' if row['score_home'] == row['score_away'] else 'Loss'), axis=1)\n",
    "nfl['team_away_result'] = nfl.apply(lambda row: 'Win' if row['score_away'] > row['score_home'] else ('Tie' if row['score_away'] == row['score_home'] else 'Loss'), axis=1)\n",
    "\n",
    "# Calculate rolling averages and statistics using pandas\n",
    "nfl = nfl.sort_values(['team_home_id', 'schedule_date'])\n",
    "\n",
    "print(nfl.head())\n",
    "\n",
    "nfl['win_pct'] = nfl.groupby('team_home_id')['team_home_result'].apply(lambda x: x.eq('Win').rolling(window=16, min_periods=1).mean())\n",
    "nfl['cover_pct'] = nfl.groupby('team_home_id')['spread_home_cover_count'].rolling(window=16, min_periods=1).mean().reset_index(0, drop=True)\n",
    "nfl['over_pct'] = nfl.groupby('team_home_id')['over_under_result_count'].rolling(window=16, min_periods=1).mean().reset_index(0, drop=True)\n",
    "\n",
    "nfl['score_avg_pts_for'] = nfl.groupby('team_home_id')['score_home'].rolling(window=16, min_periods=1).mean().reset_index(0, drop=True)\n",
    "nfl['score_avg_pts_against'] = nfl.groupby('team_home_id')['score_away'].rolling(window=16, min_periods=1).mean().reset_index(0, drop=True)\n",
    "\n",
    "# Write to CSV\n",
    "nfl.to_csv(\"nfl_calculated.csv\", index=False)\n",
    "\n",
    "# Create summary for teams\n",
    "team_summary = nfl.groupby(['team_home_id', 'schedule_season']).agg({\n",
    "    'team_home_result': ['sum'],\n",
    "    'spread_home_cover_count': ['mean'],\n",
    "    'over_under_result_count': ['mean'],\n",
    "    'score_avg_pts_for': ['mean'],\n",
    "    'score_avg_pts_against': ['mean']\n",
    "}).reset_index()\n",
    "\n",
    "team_summary.columns = ['Team', 'Season', 'Wins', 'Cover %', 'Over %', 'Off Pts/G', 'Def Pts/G']\n",
    "team_summary.to_csv(\"team_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
